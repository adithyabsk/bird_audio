{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-a612e98e87a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydub'"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction.settings import from_columns\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, EfficientFCParameters, MinimalFCParameters\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "# from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import pickle\n",
    "\n",
    "ROOT_PATH = Path(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ids, labels, and train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(ROOT_PATH / \"data/raw/metadata.csv\")\n",
    "# svc - song vs call ids\n",
    "# filter ids -> <20s, quality A & B\n",
    "# svc ids -> only rows that have call or song (not both)\n",
    "filter_ids = pd.read_json(ROOT_PATH / \"data/raw/filter_ids.json\").squeeze()\n",
    "svc_ids = pd.read_json(ROOT_PATH / \"data/raw/song_vs_call.json\").squeeze()\n",
    "svc_df = df.loc[df.id.isin(svc_ids)].copy()\n",
    "# set index to id\n",
    "svc_df.set_index('id', inplace=True)\n",
    "\n",
    "with open(ROOT_PATH / \"data/processed/svc_split.json\") as svc_split_file:\n",
    "    svc_split = json.load(svc_split_file)\n",
    "    train_ids = svc_split[\"train_ids\"]\n",
    "    test_ids = svc_split[\"test_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add response variable\n",
    "type_col = svc_df.type.str.lower().str.replace(\" \", \"\").str.split(\",\")\n",
    "filtered_type_col = type_col.apply(lambda l: set(l) - {\"call\", \"song\"})\n",
    "svc_df[\"pred\"] = type_col.apply(lambda l: \"call\" in l).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build y train-test\n",
    "# indexing all (svc_df and y_df) by id\n",
    "y_df = svc_df[\"pred\"]\n",
    "y_train, y_test = (\n",
    "    y_df[y_df.index.isin(train_ids)].squeeze(),\n",
    "    y_df[y_df.index.isin(test_ids)].squeeze(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a random smaller subset of ids and labels to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random sample of n ids from a given list of ids\n",
    "def get_rand_ids(n, ids_lst):\n",
    "    ids_ser = pd.Series(ids_lst)\n",
    "    rand_ids = ids_ser[np.random.randint(0,len(ids_lst),size=n)].array\n",
    "    return rand_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "511244    0\n",
      "268852    1\n",
      "360233    1\n",
      "345866    1\n",
      "307236    0\n",
      "54753     0\n",
      "513210    0\n",
      "59504     1\n",
      "446576    0\n",
      "472218    1\n",
      "Name: pred, dtype: int64\n",
      "id\n",
      "391159    1\n",
      "71006     0\n",
      "314230    0\n",
      "57034     1\n",
      "89171     0\n",
      "143698    1\n",
      "288789    1\n",
      "160917    1\n",
      "107700    0\n",
      "453754    1\n",
      "Name: pred, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# random subset of train\n",
    "train_rand_ids = get_rand_ids(10, train_ids)\n",
    "y_train_rand = y_train.loc[train_rand_ids]\n",
    "print(y_train_rand)\n",
    "\n",
    "# random subset of test\n",
    "test_rand_ids = get_rand_ids(10, test_ids)\n",
    "y_test_rand = y_test.loc[test_rand_ids]\n",
    "print(y_test_rand)\n",
    "\n",
    "# all rand ids\n",
    "rand_ids = np.concatenate((train_rand_ids, test_rand_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurize Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features using ts-fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply butter filter\n",
    "def highpass_filter(audio, sr):\n",
    "    # butter_coeff_b, butter_coeff_a = signal.butter(3, 1000, btype='highpass', fs=sr) # numerator and denominator\n",
    "    # butter_audio = signal.lfilter(butter_coeff_b, butter_coeff_a, audio)\n",
    "    # return butter_audio\n",
    "    return signal.lfilter(*signal.butter(3, 1000, btype='highpass', fs=sr), audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack an mp3 or wav into df of timeseries values\n",
    "def unpack_audio(id):\n",
    "    try:\n",
    "        audio_path = ROOT_PATH / (\"data/raw/recordings/\" + str(id) + \".mp3\")\n",
    "        # load mp3 as audio timeseries arr\n",
    "        timeseries,sr = librosa.load(audio_path)\n",
    "    except FileNotFoundError:\n",
    "        audio_path = ROOT_PATH / (\"data/raw/recordings/\" + str(id) + \".wav\")\n",
    "        timeseries,sr = librosa.load(audio_path)\n",
    "\n",
    "    # high-pass filter on audio timeseries\n",
    "    timeseries_filt = highpass_filter(timeseries,sr)\n",
    "\n",
    "    df = pd.DataFrame(timeseries_filt, columns=['val'])\n",
    "    df.reset_index(inplace=True)\n",
    "    df['id'] = id # fill col with id\n",
    "    df = df.reindex(columns=['id','index','val'])\n",
    "    df.columns = ['id','time','val']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "unpack_audio(svc_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select features to calculate\n",
    "# features can be found here: https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html#tsfresh.feature_extraction.feature_calculators.fft_aggregated\n",
    "extraction_settings = {\n",
    "        \"abs_energy\": None,\n",
    "        \"fft_aggregated\": [{\"aggtype\":\"centroid\"}, {\"aggtype\":\"kurtosis\"}],\n",
    "        \"root_mean_square\": None,\n",
    "        \"spkt_welch_density\": [{\"coeff\":2},{\"coeff\":5},{\"coeff\":8}]\n",
    "}\n",
    "\n",
    "def featurize_audio_manual(id):\n",
    "        return extract_features(unpack_audio(id), column_id='id', column_sort='time',\n",
    "                        default_fc_parameters=extraction_settings,\n",
    "                        disable_progressbar=True,\n",
    "                        # we impute = remove all NaN features automatically\n",
    "                        impute_function=impute,\n",
    "                        # turn off parallelization\n",
    "                        n_jobs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "kind_to_fc_parameters = {'val': {'standard_deviation': None,\n",
    "                         'variance': None,\n",
    "                         'root_mean_square': None}}\n",
    "def featurize_audio_selected(id):\n",
    "        return extract_features(unpack_audio(id), column_id='id', column_sort='time',\n",
    "                        kind_to_fc_parameters=kind_to_fc_parameters,\n",
    "                        disable_progressbar=True,\n",
    "                        # we impute = remove all NaN features automatically\n",
    "                        impute_function=impute,\n",
    "                        # turn off parallelization\n",
    "                        n_jobs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurize a single id\n",
    "# try lots of features\n",
    "def featurize_audio(id):\n",
    "    # EfficientFCParameters()\n",
    "    # ComprehensiveFCParameters()\n",
    "    # MinimalFCParameters()\n",
    "\n",
    "    return extract_features(unpack_audio(id), column_id='id', column_sort='time', \n",
    "                    default_fc_parameters=EfficientFCParameters(),\n",
    "                    disable_progressbar=True,\n",
    "                    # we impute = remove all NaN features automatically\n",
    "                    impute_function=impute,\n",
    "                    # turn off parallelization\n",
    "                    n_jobs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurize dataset\n",
    "# returns df of all\n",
    "def featurize_set(ids, feat_func):\n",
    "    X_df = pd.DataFrame()\n",
    "    for id in ids:\n",
    "        X_df = pd.concat([X_df,feat_func(id)])\n",
    "        # X_df = pd.concat([X_df,featurize_audio_manual(id)])\n",
    "        # X_df = pd.concat([X_df,featurize_audio(id)])\n",
    "        # X_df = pd.concat([X_df,featurize_audio_selected(id)])\n",
    "    return X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random subset of train\n",
    "train_rand_ids = get_rand_ids(int(len(train_ids)*.05), train_ids)\n",
    "y_train_rand = y_train.loc[train_rand_ids]\n",
    "# print(y_train_rand)\n",
    "\n",
    "# random subset of test\n",
    "test_rand_ids = get_rand_ids(int(len(test_ids)*.05), test_ids)\n",
    "y_test_rand = y_test.loc[test_rand_ids]\n",
    "# print(y_test_rand)\n",
    "\n",
    "# all rand ids\n",
    "rand_ids = np.concatenate((train_rand_ids, test_rand_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurize 5% of the dataset\n",
    "# takes 3 mins for manual, 5% of dataset\n",
    "# takes 168.2 s for minimal, 5% of dataset\n",
    "# takes 169s for selected (3 features), 5% of dataset\n",
    "X_df_rand = featurize_set(rand_ids, featurize_audio_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 1 hr\n",
    "X_df = featurize_set(svc_ids, featurize_audio_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.to_json(ROOT_PATH / f\"data/processed/audio_features_manual.json\", indent=2, orient='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test split features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train-test split of features\n",
    "\n",
    "X_train_rand, X_test_rand = (\n",
    "    X_df_rand[X_df_rand.index.isin(train_rand_ids)].squeeze(),\n",
    "    X_df_rand[X_df_rand.index.isin(test_rand_ids)].squeeze(),\n",
    ")\n",
    "\n",
    "# this gives incorrect num rows :( !\n",
    "# X_train_rand = X_df_rand.loc[train_rand_ids,:]\n",
    "# X_test_rand = X_df_rand.loc[test_rand_ids,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = pd.concat(audio_list, ignore_index=True) #crashes jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 980/5800 [50:17<4:07:18,  3.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-0c77513d6867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbuffer_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbuffer_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0maudio_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdf_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuffer_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    296\u001b[0m     )\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             new_data = concatenate_block_managers(\n\u001b[0m\u001b[1;32m    521\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             )\n",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# takes 5h\n",
    "audio_df = pd.DataFrame(columns = ['id','time','val'])\n",
    "data_size = len(svc_ids)\n",
    "buffer_size = 10\n",
    "df_buffer = [None]*buffer_size\n",
    "for idx,audio_id in enumerate(tqdm(svc_ids)):\n",
    "    buffer_idx = idx%buffer_size\n",
    "    if (buffer_idx == 0):\n",
    "        audio_df = pd.concat([audio_df]+df_buffer, ignore_index=True)\n",
    "    df_buffer[buffer_idx] = unpack_audio(audio_id)\n",
    "\n",
    "# leftover values in buffer\n",
    "leftover = data_size % buffer_size\n",
    "if (leftover != 0):\n",
    "    audio_df = pd.concat([audio_df]+df_buffer[:leftover], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 75/5800 [01:23<1:46:21,  1.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-de13d70e1017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maudio_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maudio_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0maudio_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munpack_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# takes 2h\n",
    "audio_df = pd.DataFrame(columns = ['id','time','val'])\n",
    "for audio_id in tqdm(svc_ids):  \n",
    "    audio_df = pd.concat([audio_df,unpack_audio(audio_id)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2750/5800 [31:22<34:48,  1.46it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9dbca1ad6cdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maudio_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"data/processed/audio_timeseries/{audio_id}.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_json\u001b[0;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001b[0m\n\u001b[1;32m   2464\u001b[0m         \u001b[0mindent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2466\u001b[0;31m         return json.to_json(\n\u001b[0m\u001b[1;32m   2467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mto_json\u001b[0;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         ) as handles:\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# 1h20m\n",
    "# ~80GB\n",
    "for audio_id in tqdm(svc_ids):  \n",
    "    id_df = unpack_audio(audio_id)\n",
    "    id_df.to_json(ROOT_PATH / f\"data/processed/audio_timeseries/{audio_id}.json\", indent=2, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.to_json(ROOT_PATH / \"data/processed/audio_timeseries.json\", indent=2, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5800/5800 [1:06:39<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "## Better (?) way (this takes ~1h):\n",
    "# dict[id] = df with timeseries data for that id's audio recording\n",
    "\n",
    "# audio_dict = pd.Series(index=svc_ids.head())\n",
    "audio_dict = {}\n",
    "for id in tqdm(svc_ids):\n",
    "    audio_dict[id] = unpack_audio(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5800"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ROOT_PATH / \"data/processed/audio_timeseries.pkl\", \"wb+\") as pkl_file:\n",
    "    pickle.dump(audio_dict, pkl_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random subset of train\n",
    "train_rand_ids = get_rand_ids(int(len(train_ids)*.05), train_ids)\n",
    "y_train_rand = y_train.loc[train_rand_ids]\n",
    "# print(y_train_rand)\n",
    "\n",
    "# random subset of test\n",
    "test_rand_ids = get_rand_ids(int(len(test_ids)*.05), test_ids)\n",
    "y_test_rand = y_test.loc[test_rand_ids]\n",
    "# print(y_test_rand)\n",
    "\n",
    "# all rand ids\n",
    "rand_ids = np.concatenate((train_rand_ids, test_rand_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurize 5% of the dataset\n",
    "# takes 3 mins for manual, 5% of dataset\n",
    "# takes 168.2 s for minimal, 5% of dataset\n",
    "X_df_rand = featurize_set(rand_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train-test split of features\n",
    "\n",
    "X_train_rand, X_test_rand = (\n",
    "    X_df_rand[X_df_rand.index.isin(train_rand_ids)].squeeze(),\n",
    "    X_df_rand[X_df_rand.index.isin(test_rand_ids)].squeeze(),\n",
    ")\n",
    "\n",
    "# this gives incorrect num rows :( !\n",
    "# X_train_rand = X_df_rand.loc[train_rand_ids,:]\n",
    "# X_test_rand = X_df_rand.loc[test_rand_ids,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "lr.fit(X_train_rand, y_train_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4861111111111111\n"
     ]
    }
   ],
   "source": [
    "# print(lr.score(X_test, y_test))\n",
    "print(lr.score(X_test_rand, y_test_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selected (standard_deviation, variance, root_mean_square) : .486111\n",
    "minimal : .55\n",
    "manual : .56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'val': {'standard_deviation': None,\n  'variance': None,\n  'root_mean_square': None}}"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kind_to_fc_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do extract_features in parallel - either using tsfresh n_jobs, or Process Pool Executer\n",
    "# def parallel_extract_features(id_set, params):\n",
    "#     # params are a dict of parameters for extract_features\n",
    "#     with ProcessPoolExecutor(max_workers=10) as ppe:\n",
    "#         pd.concat(\n",
    "#             list)\n",
    "#                 tqdm(\n",
    "#                     ppe.map(lambda p: extract_features(*p), download_set), total=len(id_set)\n",
    "#                 )\n",
    "#             )\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have ts-fresh figure out which features are good\n",
    "# presets can be found here: https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html#tsfresh.feature_extraction.settings.ComprehensiveFCParameters\n",
    "# with more details here: https://tsfresh.readthedocs.io/en/latest/_modules/tsfresh/feature_extraction/settings.html#MinimalFCParameters\n",
    "\n",
    "# X_df_autofilt = extract_relevant_features(audio_df_head, y_train.loc[rand_ids], \n",
    "# # X_df_autofilt = extract_relevant_features(audio_df_head, y_train.iloc[rand_idx], \n",
    "# # X_df_autofilt = extract_relevant_features(audio_df, y_train, \n",
    "#                                             column_id='id', column_sort='time', \n",
    "#                                             default_fc_parameters=MinimalFCParameters(), n_jobs=0)\n",
    "# get X and y \n",
    "y_for_selected = y_train.loc[feat_select_ids]\n",
    "X_selected = select_features(X_extracted, y)\n",
    "\n",
    "# get a dictionary of the good features parameters, to use again later\n",
    "kind_to_fc_parameters = from_columns(X_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the selected features from full dataset\n",
    "X_df = extract_features(audio_df, column_id='id', column_sort='time',\n",
    "                     default_fc_parameters=kind_to_fc_parameters,\n",
    "                     # we impute = remove all NaN features automatically\n",
    "                     impute_function=impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# feature_mapper = DataFrameMapper(\n",
    "#     [\n",
    "#         (\"id\", None),\n",
    "#         ([\"gen\"], OneHotEncoder()),\n",
    "#         ([\"sp\"], OneHotEncoder()),\n",
    "#         ([\"ssp\"], OneHotEncoder()),\n",
    "#         ([\"en\"], OneHotEncoder()),\n",
    "#         ([\"lat\"], [MinMaxScaler(), SimpleImputer()]),\n",
    "#         ([\"lng\"], [MinMaxScaler(), SimpleImputer()]),\n",
    "#         ([\"gender\"], OneHotEncoder()),\n",
    "#         ([\"age\"], OneHotEncoder()),\n",
    "#     ],\n",
    "#     df_out=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X_feat_df = feature_mapper.fit_transform(X_df)\n",
    "# X_train, X_test = (\n",
    "#     X_df[X_df.id.isin(train_ids)].drop(columns=[\"id\"]),\n",
    "#     X_df[X_df.id.isin(test_ids)].drop(columns=[\"id\"]),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "lr.fit(X_train_rand, y_train_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3888888888888889\n"
     ]
    }
   ],
   "source": [
    "# print(lr.score(X_test, y_test))\n",
    "print(lr.score(X_test_rand, y_test_rand))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "9d6766ad3736c29ebfe40ecf2d41a2944950e1cce237755c2a58ee0718f8bfc6"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "9d6766ad3736c29ebfe40ecf2d41a2944950e1cce237755c2a58ee0718f8bfc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}