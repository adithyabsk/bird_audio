{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction.settings import from_columns\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, EfficientFCParameters, MinimalFCParameters\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import pickle\n",
    "\n",
    "ROOT_PATH = Path(\"..\")"
   ]
  },
  {
   "source": [
    "## Get ids, labels, and train-test splits"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv(ROOT_PATH / \"data/raw/metadata.csv\")\n",
    "# svc - song vs call ids\n",
    "# filter ids -> <20s, quality A & B\n",
    "# svc ids -> only rows that have call or song (not both)\n",
    "filter_ids = pd.read_json(ROOT_PATH / \"data/raw/filter_ids.json\").squeeze()\n",
    "svc_ids = pd.read_json(ROOT_PATH / \"data/raw/song_vs_call.json\").squeeze()\n",
    "svc_df = df.loc[df.id.isin(svc_ids)].copy()\n",
    "# set index to id\n",
    "svc_df.set_index('id', inplace=True)\n",
    "\n",
    "with open(ROOT_PATH / \"data/processed/svc_split.json\") as svc_split_file:\n",
    "    svc_split = json.load(svc_split_file)\n",
    "    train_ids = svc_split[\"train_ids\"]\n",
    "    test_ids = svc_split[\"test_ids\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add response variable\n",
    "type_col = svc_df.type.str.lower().str.replace(\" \", \"\").str.split(\",\")\n",
    "filtered_type_col = type_col.apply(lambda l: set(l) - {\"call\", \"song\"})\n",
    "svc_df[\"pred\"] = type_col.apply(lambda l: \"call\" in l).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## svc_df indexed by index\n",
    "# Build y train-test\n",
    "# y_df = svc_df.reindex(columns=[\"id\", \"pred\"]).copy()\n",
    "# index by index\n",
    "# y_train, y_test = (\n",
    "#     y_df[y_df.id.isin(train_ids)].drop(columns=[\"id\"]).squeeze(),\n",
    "#     y_df[y_df.id.isin(test_ids)].drop(columns=[\"id\"]).squeeze(),\n",
    "# )\n",
    "# index by id\n",
    "# y_train, y_test = (\n",
    "#     y_df[y_df.id.isin(train_ids)].set_index('id').squeeze(),\n",
    "#     y_df[y_df.id.isin(test_ids)].set_index('id').squeeze(),\n",
    "# )\n",
    "\n",
    "## svc_df indexed by id\n",
    "# index all (svc_df and y_df) by id\n",
    "y_df = svc_df[\"pred\"]\n",
    "y_train, y_test = (\n",
    "    y_df[y_df.index.isin(train_ids)].squeeze(),\n",
    "    y_df[y_df.index.isin(test_ids)].squeeze(),\n",
    ")"
   ]
  },
  {
   "source": [
    "### Get a random smaller subset of ids and labels to work with"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with a smaller subset of recordings\n",
    "# index by id\n",
    "train_ids_ser = pd.Series(train_ids)\n",
    "train_rand_ids = train_ids_ser[np.random.randint(0,len(train_ids),size=10)].array\n",
    "y_train_rand = y_train.loc[train_rand_ids]\n",
    "print(y_train_rand)\n",
    "\n",
    "# rand_idx = train_ids_ser[np.random.randint(0,len(train_ids),size=10)].index\n",
    "# y_train.iloc[rand_idx] # check that we have both labels\n",
    "\n",
    "\n",
    "\n",
    "# test with a smaller subset of recordings\n",
    "# index by id\n",
    "test_ids_ser = pd.Series(test_ids)\n",
    "test_rand_ids = test_ids_ser[np.random.randint(0,len(test_ids),size=10)].array\n",
    "y_test_rand = y_test.loc[test_rand_ids]\n",
    "print(y_test_rand)\n",
    "\n",
    "# test_rand_idx = test_ids_ser[np.random.randint(0,len(test_ids),size=10)].index\n",
    "# y_test.iloc[test_rand_idx] # check that we have both labels\n",
    "\n",
    "\n",
    "# all rand ids\n",
    "rand_ids = np.concatenate((train_rand_ids, test_rand_ids))\n",
    "rand_ids"
   ]
  },
  {
   "source": [
    "## Unpack and filter audio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highpass_filter(audio, sr):\n",
    "    # # apply Butter filter\n",
    "    # butter_coeff_b, butter_coeff_a = signal.butter(3, 1000, btype='highpass', fs=sr) # numerator and denominator\n",
    "    # butter_audio = signal.lfilter(butter_coeff_b, butter_coeff_a, audio)\n",
    "    # return butter_audio\n",
    "    return signal.lfilter(*signal.butter(3, 1000, btype='highpass', fs=sr), audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_audio(id):\n",
    "    try:\n",
    "        audio_path = ROOT_PATH / (\"data/raw/recordings/\" + str(id) + \".mp3\")\n",
    "        # load mp3 as audio timeseries arr\n",
    "        timeseries,sr = librosa.load(audio_path)\n",
    "    except FileNotFoundError:\n",
    "        audio_path = ROOT_PATH / (\"data/raw/recordings/\" + str(id) + \".wav\")\n",
    "        timeseries,sr = librosa.load(audio_path)\n",
    "\n",
    "    # timeseries = timeseries[1000:2000] # reduce size\n",
    "    # high-pass filter on audio timeseries\n",
    "    timeseries_filt = highpass_filter(timeseries,sr)\n",
    "\n",
    "    df = pd.DataFrame(timeseries_filt, columns=['val'])\n",
    "    df.reset_index(inplace=True)\n",
    "    df['id'] = id\n",
    "    df = df.reindex(columns=['id','index','val'])\n",
    "    df.columns = ['id','time','val']\n",
    "    return df\n",
    "    # num_samples = len(timeseries_filt)\n",
    "    # return pd.DataFrame(list(zip([id]*num_samples,range(num_samples),timeseries_filt)),columns=['id','time','val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.16 s ± 34.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "unpack_audio(svc_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "806 ms ± 14.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "unpack_audio(svc_ids[0])"
   ]
  },
  {
   "source": [
    "### Save audio timeseries data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying to unpack all audio in a vertically stacked df (this is WAY too many rows)\n",
    "# concatenate in batches? concat to what i have already\n",
    "\n",
    "# audio_df_head = pd.concat([unpack_audio(id) for id in rand_ids], ignore_index=True)\n",
    "# audio_df_head = pd.concat([unpack_audio(id) for id in svc_ids[rand_idx].array], ignore_index=True)\n",
    "# audio_df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5800/5800 [50:00<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "audio_list = [unpack_audio(id) for id in tqdm(svc_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df = pd.concat(audio_list, ignore_index=True) #crashes jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 17%|█▋        | 980/5800 [50:17<4:07:18,  3.08s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-0c77513d6867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbuffer_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbuffer_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0maudio_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdf_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuffer_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    296\u001b[0m     )\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             new_data = concatenate_block_managers(\n\u001b[0m\u001b[1;32m    521\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             )\n",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# takes 5h\n",
    "audio_df = pd.DataFrame(columns = ['id','time','val'])\n",
    "data_size = len(svc_ids)\n",
    "buffer_size = 10\n",
    "df_buffer = [None]*buffer_size\n",
    "for idx,audio_id in enumerate(tqdm(svc_ids)):\n",
    "    buffer_idx = idx%buffer_size\n",
    "    if (buffer_idx == 0):\n",
    "        audio_df = pd.concat([audio_df]+df_buffer, ignore_index=True)\n",
    "    df_buffer[buffer_idx] = unpack_audio(audio_id)\n",
    "\n",
    "# leftover values in buffer\n",
    "leftover = data_size % buffer_size\n",
    "if (leftover != 0):\n",
    "    audio_df = pd.concat([audio_df]+df_buffer[:leftover], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|▏         | 75/5800 [01:23<1:46:21,  1.11s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-de13d70e1017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maudio_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maudio_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0maudio_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munpack_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# takes 2h\n",
    "audio_df = pd.DataFrame(columns = ['id','time','val'])\n",
    "for audio_id in tqdm(svc_ids):  \n",
    "    audio_df = pd.concat([audio_df,unpack_audio(audio_id)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "302534"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "svc_ids[2750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 47%|████▋     | 2750/5800 [31:22<34:48,  1.46it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9dbca1ad6cdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maudio_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"data/processed/audio_timeseries/{audio_id}.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_json\u001b[0;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001b[0m\n\u001b[1;32m   2464\u001b[0m         \u001b[0mindent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2466\u001b[0;31m         return json.to_json(\n\u001b[0m\u001b[1;32m   2467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CMU/21S/DataScience/final/pracds_final/venv/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mto_json\u001b[0;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         ) as handles:\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# 1h20m\n",
    "# ~80GB\n",
    "for audio_id in tqdm(svc_ids):  \n",
    "    id_df = unpack_audio(audio_id)\n",
    "    id_df.to_json(ROOT_PATH / f\"data/processed/audio_timeseries/{audio_id}.json\", indent=2, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.to_json(ROOT_PATH / \"data/processed/audio_timeseries.json\", indent=2, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5800/5800 [1:06:39<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "## Better (?) way (this takes ~1h):\n",
    "# dict[id] = df with timeseries data for that id's audio recording\n",
    "\n",
    "# audio_dict = pd.Series(index=svc_ids.head())\n",
    "audio_dict = {}\n",
    "for id in tqdm(svc_ids):\n",
    "    audio_dict[id] = unpack_audio(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5800"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "len(audio_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ROOT_PATH / \"data/processed/audio_timeseries.pkl\", \"wb+\") as pkl_file:\n",
    "    pickle.dump(audio_dict, pkl_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "source": [
    "## Extract features using ts-fresh"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do extract_features in parallel - either using tsfresh n_jobs, or Process Pool Executer\n",
    "# def parallel_extract_features(id_set, params):\n",
    "#     # params are a dict of parameters for extract_features\n",
    "#     with ProcessPoolExecutor(max_workers=10) as ppe:\n",
    "#         pd.concat(\n",
    "#             list)\n",
    "#                 tqdm(\n",
    "#                     ppe.map(lambda p: extract_features(*p), download_set), total=len(id_set)\n",
    "#                 )\n",
    "#             )\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select features to calculate\n",
    "# features can be found here: https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html#tsfresh.feature_extraction.feature_calculators.fft_aggregated\n",
    "\n",
    "extraction_settings = {\n",
    "    \"abs_energy\": None,\n",
    "    \"fft_aggregated\": [{\"aggtype\":\"centroid\"}, {\"aggtype\":\"kurtosis\"}],\n",
    "    \"root_mean_square\": None,\n",
    "    \"spkt_welch_density\": [{\"coeff\":2},{\"coeff\":5},{\"coeff\":8}]\n",
    "}\n",
    "\n",
    "X_df_manual = extract_features(audio_df, column_id='id', column_sort='time',\n",
    "# X_df_manual = extract_features(audio_df_head, column_id='id', column_sort='time',\n",
    "                     default_fc_parameters=extraction_settings,\n",
    "                     # we impute = remove all NaN features automatically\n",
    "                     impute_function=impute,\n",
    "                     # turn off parallelization\n",
    "                     n_jobs=0)\n",
    "X_df_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5800"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "len(svc_ids)"
   ]
  },
  {
   "source": [
    "### Select features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random sample of 10% of ids from training data for feature selection\n",
    "percent = .10\n",
    "train_ids_ser = pd.Series(train_ids)\n",
    "feat_select_ids = train_ids_ser[np.random.randint(0,len(train_ids),size=int(len(train_ids)*percent))].array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try lots of features\n",
    "\n",
    "# get X and y \n",
    "y_for_selected = y_train.loc[feat_select_ids]\n",
    "\n",
    "# EfficientFCParameters()\n",
    "\n",
    "X_extracted = extract_features(audio_df[feat_select_ids], column_id='id', column_sort='time', \n",
    "                    default_fc_parameters=ComprehensiveFCParameters(),\n",
    "                    # we impute = remove all NaN features automatically\n",
    "                    impute_function=impute)\n",
    "                    # turn off parallelization\n",
    "                    # n_jobs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have ts-fresh figure out which features are good\n",
    "# presets can be found here: https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html#tsfresh.feature_extraction.settings.ComprehensiveFCParameters\n",
    "# with more details here: https://tsfresh.readthedocs.io/en/latest/_modules/tsfresh/feature_extraction/settings.html#MinimalFCParameters\n",
    "\n",
    "# X_df_autofilt = extract_relevant_features(audio_df_head, y_train.loc[rand_ids], \n",
    "# # X_df_autofilt = extract_relevant_features(audio_df_head, y_train.iloc[rand_idx], \n",
    "# # X_df_autofilt = extract_relevant_features(audio_df, y_train, \n",
    "#                                             column_id='id', column_sort='time', \n",
    "#                                             default_fc_parameters=MinimalFCParameters(), n_jobs=0)\n",
    "X_selected = select_features(X_extracted, y)\n",
    "\n",
    "# get a dictionary of the good features parameters, to use again later\n",
    "kind_to_fc_parameters = from_columns(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the selected features from full dataset\n",
    "X_df = extract_features(audio_df, column_id='id', column_sort='time',\n",
    "                     default_fc_parameters=kind_to_fc_parameters,\n",
    "                     # we impute = remove all NaN features automatically\n",
    "                     impute_function=impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# feature_mapper = DataFrameMapper(\n",
    "#     [\n",
    "#         (\"id\", None),\n",
    "#         ([\"gen\"], OneHotEncoder()),\n",
    "#         ([\"sp\"], OneHotEncoder()),\n",
    "#         ([\"ssp\"], OneHotEncoder()),\n",
    "#         ([\"en\"], OneHotEncoder()),\n",
    "#         ([\"lat\"], [MinMaxScaler(), SimpleImputer()]),\n",
    "#         ([\"lng\"], [MinMaxScaler(), SimpleImputer()]),\n",
    "#         ([\"gender\"], OneHotEncoder()),\n",
    "#         ([\"age\"], OneHotEncoder()),\n",
    "#     ],\n",
    "#     df_out=True,\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_feat_df = feature_mapper.fit_transform(X_df)\n",
    "# X_train, X_test = (\n",
    "#     X_df[X_df.id.isin(train_ids)].drop(columns=[\"id\"]),\n",
    "#     X_df[X_df.id.isin(test_ids)].drop(columns=[\"id\"]),\n",
    "# )\n",
    "\n",
    "X_train, X_test = (\n",
    "    X_df[X_df.index.isin(train_rand_ids)].squeeze(),\n",
    "    X_df[X_df.index.isin(test_rand_ids)].squeeze(),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "# lr.fit(X_train, y_train_rand)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(lr.score(X_test, y_test))\n",
    "# print(lr.score(X_test, y_test_rand))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd09d6766ad3736c29ebfe40ecf2d41a2944950e1cce237755c2a58ee0718f8bfc6",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "9d6766ad3736c29ebfe40ecf2d41a2944950e1cce237755c2a58ee0718f8bfc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}